{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Assignment Week 10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizzierobinson2/coolcode/blob/master/Copy_of_Assignment_Week_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s6mU2pbouTC"
      },
      "source": [
        "**FUN WITH TEXT FILES**\n",
        "\n",
        "In the worksheet this week, we had a bunch of examples of working with text in an external file. In the assignment, we will build on the examples in the Worksheet. \n",
        "\n",
        "You can find the worksheet here: https://github.com/mlepinski/Python-Worksheets/blob/master/Week_10_Worksheet.ipynb\n",
        "\n",
        "1) Write a function, **count_lines** that takes in a file name as input to the function. (That is, as a parameter to the function, you don't want someone to have to type a URL at the keyboard). You function should loop through the lines in the file and count how many lines there are. \n",
        "\n",
        "If you write your function correctly, the following test code should work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16X9PdJ-MMW"
      },
      "source": [
        "import urllib.request \n",
        "\n",
        "def count_lines(url_file):\n",
        "  file_open = urllib.request.urlopen(url_file)\n",
        "  linebyline = []\n",
        "  number = 0\n",
        "  for line in file_open:\n",
        "    line = line.decode('utf-8')\n",
        "    number = number + 1\n",
        "  return number\n",
        "      "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB2Sfz41osfq",
        "outputId": "f502dd36-418d-4865-8a03-015081f6ca43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_name1 = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/Sonnets.txt\"\n",
        "answer1 = count_lines(file_name1)\n",
        "\n",
        "file_name2 = file_name = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/coolWords.txt\"\n",
        "answer2 = count_lines(file_name2)\n",
        "\n",
        "print(\"First file number of lines:\" , answer1)\n",
        "print(\"Second file number of lines:\" , answer2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First file number of lines: 2617\n",
            "Second file number of lines: 718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UbHZq45q1gy"
      },
      "source": [
        "2) Write a function, **lines_with_word** that takes two as input both a file name and a word and counts how many lines in the file contain the word. \n",
        "\n",
        "Note: If the word is \"war\" it is perfectly fine (as in the Worksheet) to count lines with \"warm\" or \"warning\" as long as the letters \"war\" are somewhere on the line.\n",
        "\n",
        "Here is some test code: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVSWTVnABB65"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "def lines_with_word(file_name, word_chosen):\n",
        "  file_1 = urllib.request.urlopen(file_name)\n",
        "  word_count = 0\n",
        "  for line in file_1:\n",
        "    line = line.decode('utf-8')\n",
        "    if word_chosen in line:\n",
        "      word_count = word_count + 1\n",
        "  return word_count\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ryky4nADks",
        "outputId": "b85ec972-98b1-41c5-d018-0aa610c41f49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_name = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/Sonnets.txt\"\n",
        "answer1 = lines_with_word(file_name, \"monuments\")\n",
        "\n",
        "print(\"monuments appears in \", answer1, \"lines\")\n",
        "\n",
        "answer2 = lines_with_word(file_name, \"war\")\n",
        "\n",
        "print(\"war appears in \", answer2, \"lines\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "monuments appears in  1 lines\n",
            "war appears in  39 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeI-gGmMrh5c"
      },
      "source": [
        "3) Modify your previous function **lines_with_word** so that it converts the entire line to lowercase before looking for the given word. (This way, if the word is \"shall\" and the line contains \"Shall\", it will still get counted.)\n",
        "\n",
        "Note: Your new function and your old function should give different answers with the input \"shall\" because sometimes \"shall\" is capitolized (\"Shall\") in the file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob-hFZXo8srs",
        "outputId": "995156da-1753-403d-9585-30ccb1894713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "def lines_with_word(file_name, word_chosen):\n",
        "  \n",
        "  file_1 = urllib.request.urlopen(file_name)\n",
        "  word_chosen = word_chosen.lower()\n",
        "\n",
        "  word_count = 0\n",
        "\n",
        "  for line in file_1:\n",
        "    line = line.lower()\n",
        "    line = line.decode('utf-8')\n",
        "    if word_chosen in line:\n",
        "      word_count = word_count + 1\n",
        "  return word_count\n",
        "\n",
        "file_name = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/Sonnets.txt\"\n",
        "answer1 = lines_with_word(file_name, \"shall\")\n",
        "\n",
        "print(\"shall appears in \", answer1, \"lines\")\n",
        "\n",
        "answer2 = lines_with_word(file_name, \"war\")\n",
        "\n",
        "print(\"war appears in \", answer2, \"lines\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shall appears in  59 lines\n",
            "war appears in  39 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mor-eu6sHo-"
      },
      "source": [
        "4) Write a function **word_count** that takes as input a file name and a word and returns how many times the word appears in the file. \n",
        "\n",
        "Your function is counting occurances of the word and not lines. Also, for this problem please match the word exactly (so if you are looking for \"war\", don't count \"warm\" or \"warning\"). \n",
        "\n",
        "Also, as in question 3, your function should match regardless of whether the word in the file is upper case or lower case.\n",
        "\n",
        "Here is some example code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCXnqkd58vBu"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "def word_count(file_name, word):\n",
        "  word = word.lower()\n",
        "\n",
        "  file_1 = urllib.request.urlopen(file_name)\n",
        "\n",
        "  string_long = file_1.read()\n",
        "  string_long = string_long.decode('utf-8')\n",
        "  string_long = string_long.lower()\n",
        "\n",
        "  no_breaks = string_long.replace('\\n',' ')\n",
        "\n",
        "  string_list = no_breaks.split()\n",
        "\n",
        "  word_count = 0\n",
        "\n",
        "  for word_s in string_list:\n",
        "    if word_s == word:\n",
        "      word_count = word_count + 1\n",
        "  return word_count"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx42q67ysHF0",
        "outputId": "94c39f4c-695b-411f-e8b0-a6e80f34c916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_name = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/Sonnets.txt\"\n",
        "answer1 = word_count(file_name, \"monuments\")\n",
        "\n",
        "print(\"monuments appears \", answer1, \"times\")\n",
        "\n",
        "answer2 = word_count(file_name, \"war\")\n",
        "\n",
        "print(\"war appears times\", answer2, \"times\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "monuments appears  1 times\n",
            "war appears times 6 times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1g7_zq0sjCN"
      },
      "source": [
        "5) It is probably the case that your function in number 4 doesn't handle punctuation very well. \n",
        "\n",
        "If you are looking for \"warm\" and you find \"warm,\" you ideally want \"warm,\" to be counted even though there is a comma present. \n",
        "\n",
        "Modify your **word_count** function so that you remove punctuation like commas, periods, and semi-colons from the file before you go and count the words. \n",
        "\n",
        "If you do this correctly, your new function should give you different answers for words like \"memory\" and \"fuel\" which appear in the file attached to puncuation marks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtpXHp-YLLjj"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "def word_count(file_name, word):\n",
        "  word = word.lower()\n",
        "\n",
        "  file_1 = urllib.request.urlopen(file_name)\n",
        "\n",
        "  string_long = file_1.read()\n",
        "  string_long = string_long.decode('utf-8')\n",
        "  string_long = string_long.lower()\n",
        "\n",
        "  no_breaks = string_long.replace('\\n',' ')\n",
        "  commas = no_breaks.replace(',', ' ')\n",
        "  semi_colon = commas.replace(';', ' ')\n",
        "  colon = semi_colon.replace(':', ' ')\n",
        "  periods = colon.replace('.', ' ')\n",
        "\n",
        "\n",
        "  string_list = periods.split()\n",
        "\n",
        "  word_count = 0\n",
        "\n",
        "  for word_s in string_list:\n",
        "    if word_s == word:\n",
        "      word_count = word_count + 1\n",
        "  return word_count"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGSCNxmDhtGP",
        "outputId": "5aff1c0c-91b7-491b-df0f-668a83ca8c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_name = \"https://raw.githubusercontent.com/mlepinski/Python-Worksheets/master/Sonnets.txt\"\n",
        "answer1 = word_count(file_name, \"memory\")\n",
        "\n",
        "print(\"memory appears \", answer1, \"times\")\n",
        "\n",
        "answer2 = word_count(file_name, \"fuel\")\n",
        "\n",
        "print(\"fuel appears times\", answer2, \"times\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory appears  8 times\n",
            "fuel appears times 6 times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hexbcc9qsxB8"
      },
      "source": [
        "6) Write a function **word_frequency** that takes in a file name and a file_name and a word as input to the function and returns what percentage of the words in the file match a particular word. \n",
        "\n",
        "That is, you should count the total number of words and divide your word count by the total to get a percentage frequency. This will tell you how often the word appears and could allow you to compare frequencies across files with different lengths. \n",
        "\n",
        "Note: An excellent way to do this is to have your **word_frequency** function make a call to your **word_count** function from the previous problem. \n",
        "\n",
        "You don't have to do this, but now that you have a **word_frequency** function it would be fun to grab another text file from somewhere (it could be something that you have written or something from project Guttenberg) and stick it in your Github. Then use your **word_frequency** function to see if there are certain words (e.g. \"thee\" or maybe even \"shall\") that are used more often by Shakespeare in his sonnets than in the other text file that you found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIIbidk3LMG5",
        "outputId": "e190286b-9aab-49b2-db43-bcc03beb01e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "def word_frequency(file_name, word):\n",
        "  word = word.lower()\n",
        "\n",
        "  file_1 = urllib.request.urlopen(file_name)\n",
        "\n",
        "  string_long = file_1.read()\n",
        "  string_long = string_long.decode('utf-8')\n",
        "  string_long = string_long.lower()\n",
        "\n",
        "  no_breaks = string_long.replace('\\n',' ')\n",
        "  commas = no_breaks.replace(',', ' ')\n",
        "  semi_colon = commas.replace(';', ' ')\n",
        "  colon = semi_colon.replace(':', ' ')\n",
        "  periods = colon.replace('.', ' ')\n",
        "\n",
        "\n",
        "  list_of_words = periods.split()\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for any_word in list_of_words:\n",
        "    count = count + 1\n",
        "\n",
        "  percent = word_count(file_name, word) / count\n",
        "  real_percent = percent * 100\n",
        "  return real_percent\n",
        "\n",
        "file_name = 'http://www.gutenberg.org/cache/epub/63573/pg63573.txt'\n",
        "answer = word_frequency(file_name, 'bridge')\n",
        "print(answer)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0997506234413965\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}